{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imshow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(gpu_fraction=0.25):    \n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction, allow_growth=True)    \n",
    "    return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "keras.backend.set_session(get_session())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare variables to be used later.  MAKE SURE TO DOUBLE CHECK THESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all images are square\n",
    "image_size = 230\n",
    "\n",
    "# Need to change this to match category count\n",
    "num_categories = 8\n",
    "\n",
    "\n",
    "# Change this for number of images to be in train and test set\n",
    "trainsize = 2000\n",
    "testsize = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import image data and convert response to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genrePath = os.path.join('/team', 'scratch', 'album-ai', 'data', 'genres.csv')\n",
    "\n",
    "genres = pd.read_csv(genrePath)\n",
    "genres = genres.loc[genres['genre'] != 'unknown']\n",
    "\n",
    "genre_dict = {'pop':0, \n",
    "              'rock':1, \n",
    "              'country':2,\n",
    "              'folk':2,\n",
    "              'rap':3,\n",
    "              'hip hop':3,\n",
    "              'metal':4, \n",
    "              'indie':5, \n",
    "              'electronic':6, \n",
    "              'classical':7}\n",
    "\n",
    "genres['genre_id'] = genres['genre'].map(genre_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to convert image to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg_image_to_array(image_path):\n",
    "    \"\"\"\n",
    "    Loads JPEG image into 3D Numpy array of shape \n",
    "    (width, height, channels)\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as image:         \n",
    "        im_arr = np.frombuffer(image.tobytes(), dtype=np.uint8)\n",
    "        im_arr = im_arr.reshape((image.size[1], image.size[0], 3))                                   \n",
    "    return im_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull actual resized image data.  Array will be 230 by 230 by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata():\n",
    "    covers = os.path.join('/team', 'scratch', 'album-ai', 'data', 'resizedArt')\n",
    "\n",
    "    trainx = np.array([], dtype=np.uint8)\n",
    "    trainy = []\n",
    "    \n",
    "    loggingCount = 0\n",
    "\n",
    "    for file in list(genres['id'])[0:trainsize]:\n",
    "        image_arr = jpg_image_to_array(os.path.join(covers, str(file) + '.jpg'))\n",
    "        image_arr = image_arr[np.newaxis, :]\n",
    "        trainx = np.vstack((trainx, image_arr)).astype('uint8') if trainx.size else image_arr\n",
    "        trainy.append(int(genres[genres['id'] == file]['genre_id']))\n",
    "        \n",
    "        loggingCount += 1\n",
    "        if loggingCount % 100 == 0:\n",
    "            print('{} out of {} training albums imported'.format(loggingCount, trainsize))\n",
    "\n",
    "    trainy = np.asarray(trainy)\n",
    "\n",
    "    testx = np.array([], dtype=np.uint8)\n",
    "    testy = []\n",
    "    \n",
    "    loggingCount = 0\n",
    "\n",
    "    for file in list(genres['id'])[trainsize:trainsize + testsize]:\n",
    "        image_arr = jpg_image_to_array(os.path.join(covers, str(file) + '.jpg'))\n",
    "        image_arr = image_arr[np.newaxis, :]\n",
    "        testx = np.vstack((testx, image_arr)).astype('uint8') if testx.size else image_arr\n",
    "        testy.append(int(genres[genres['id'] == file]['genre_id']))\n",
    "        \n",
    "        loggingCount += 1\n",
    "        if loggingCount % 100 == 0:\n",
    "            print('{} out of {} testing albums imported'.format(loggingCount, testsize))\n",
    "\n",
    "    testy = np.asarray(testy)\n",
    "    \n",
    "    return trainx, trainy, testx, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.fromarray(testx[1])\n",
    "\n",
    "%matplotlib inline\n",
    "# imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformdata():\n",
    "    trainx, trainy, testx, testy = loaddata()\n",
    "    trainx = trainx/255.\n",
    "    testx = testx/255.\n",
    "    trainy = to_categorical(trainy,num_categories)\n",
    "    testy = to_categorical(testy,num_categories)\n",
    "    trainx = np.reshape(trainx,(len(trainx),image_size*image_size*3))\n",
    "    testx = np.reshape(testx,(len(testx),image_size*image_size*3))\n",
    "    return trainx,trainy,testx,testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    inp = Input(shape=(image_size*image_size*3,))\n",
    "    d1 = Dense(128,activation='relu')(inp)\n",
    "    d2 = Dense(128,activation='relu')(d1)\n",
    "    out = Dense(num_categories,activation='softmax')(d2)\n",
    "    model = Model(inputs=inp,outputs=out)\n",
    "    sgd = optimizers.SGD(lr=0.01)\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(trainx, trainy, testx, testy):\n",
    "    address = './models/'\n",
    "    if not os.path.exists(address):\n",
    "        os.makedirs(address)\n",
    "    saved_model = address + \"model.h5\"\n",
    "    model = build_model1()\n",
    "    stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "    save = ModelCheckpoint(saved_model, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "    print(\"Start training\")\n",
    "    hist = model.fit(trainx,trainy,\n",
    "                     callbacks=[stop,save],validation_split=0.2,\n",
    "                     epochs=50,batch_size=100)\n",
    "    print('Delete current model')\n",
    "    del model\n",
    "    print('Load saved model')\n",
    "    model = load_model(saved_model)\n",
    "    score = model.evaluate(testx,testy)\n",
    "    print('Test loss: {:08.5f} ...Test accuracy: {:06.2f}%'.format(score[0],score[1]*100)) \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell imports the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 out of 2000 training albums imported\n",
      "200 out of 2000 training albums imported\n",
      "300 out of 2000 training albums imported\n",
      "400 out of 2000 training albums imported\n",
      "500 out of 2000 training albums imported\n",
      "600 out of 2000 training albums imported\n",
      "700 out of 2000 training albums imported\n",
      "800 out of 2000 training albums imported\n",
      "900 out of 2000 training albums imported\n",
      "1000 out of 2000 training albums imported\n",
      "1100 out of 2000 training albums imported\n",
      "1200 out of 2000 training albums imported\n",
      "1300 out of 2000 training albums imported\n",
      "1400 out of 2000 training albums imported\n",
      "1500 out of 2000 training albums imported\n",
      "1600 out of 2000 training albums imported\n",
      "1700 out of 2000 training albums imported\n",
      "1800 out of 2000 training albums imported\n",
      "1900 out of 2000 training albums imported\n",
      "2000 out of 2000 training albums imported\n"
     ]
    }
   ],
   "source": [
    "# Only need to run this cell when changing the training and testing data\n",
    "# Takes several minutes to run for large numbers of images\n",
    "\n",
    "trainx, trainy, testx, testy = transformdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the model and trains it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Start training\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 4s 3ms/sample - loss: 5.0538 - acc: 0.1931 - val_loss: 1.9815 - val_acc: 0.0325\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 1.9478 - acc: 0.2544 - val_loss: 2.0713 - val_acc: 0.3750\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 1.9262 - acc: 0.2706 - val_loss: 2.1187 - val_acc: 0.0350\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 1.9240 - acc: 0.2750 - val_loss: 2.1348 - val_acc: 0.3775\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 1.9210 - acc: 0.2575 - val_loss: 2.1982 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 1.9104 - acc: 0.2694 - val_loss: 2.0543 - val_acc: 0.3900\n",
      "Epoch 00006: early stopping\n",
      "Delete current model\n",
      "Load saved model\n",
      "10/10 [==============================] - 0s 5ms/sample - loss: 1.5427 - acc: 0.1000\n",
      "Test loss: 01.54269 ...Test accuracy: 010.00%\n"
     ]
    }
   ],
   "source": [
    "# Run this cell when changing the model\n",
    "\n",
    "main(trainx, trainy, testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
